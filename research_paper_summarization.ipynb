{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOg+hLV4qlM+7LyA9YGuF/2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QFUycdE5hLOL","executionInfo":{"status":"ok","timestamp":1754386791788,"user_tz":-345,"elapsed":7017,"user":{"displayName":"Dinesh Tamang","userId":"12691506856444135406"}},"outputId":"c509dde5-81d0-4c42-cdbf-26aeccbf5269"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: arxiv in /usr/local/lib/python3.11/dist-packages (2.2.0)\n","Requirement already satisfied: feedparser~=6.0.10 in /usr/local/lib/python3.11/dist-packages (from arxiv) (6.0.11)\n","Requirement already satisfied: requests~=2.32.0 in /usr/local/lib/python3.11/dist-packages (from arxiv) (2.32.3)\n","Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.11/dist-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (2025.7.14)\n"]}],"source":["import pandas as pd\n","!pip install arxiv"]},{"cell_type":"code","source":["import arxiv\n","!pip install transformers\n","from transformers import pipeline"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1hitgcz1hcG6","executionInfo":{"status":"ok","timestamp":1754386810109,"user_tz":-345,"elapsed":18293,"user":{"displayName":"Dinesh Tamang","userId":"12691506856444135406"}},"outputId":"eca47a70-4509-488d-8cae-fc4ceaf431cb"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n"]}]},{"cell_type":"code","source":["query='ai OR machine learnin OR artificial intelligence'\n","search=arxiv.Search(query=query,max_results=10,sort_by=arxiv.SortCriterion.SubmittedDate)"],"metadata":{"id":"ButEspNVh_ry","executionInfo":{"status":"ok","timestamp":1754386810127,"user_tz":-345,"elapsed":16,"user":{"displayName":"Dinesh Tamang","userId":"12691506856444135406"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["for result in search.results():\n","  print(dir(result))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HmcS9TYIjG_g","executionInfo":{"status":"ok","timestamp":1754386810626,"user_tz":-345,"elapsed":482,"user":{"displayName":"Dinesh Tamang","userId":"12691506856444135406"}},"outputId":"2dba542e-bc15-49c8-93b4-d78fdc535a65"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1887795096.py:1: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n","  for result in search.results():\n"]},{"output_type":"stream","name":"stdout","text":["['Author', 'Link', 'MissingFieldError', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_from_feed_entry', '_get_default_filename', '_get_pdf_url', '_raw', '_substitute_domain', '_to_datetime', 'authors', 'categories', 'comment', 'doi', 'download_pdf', 'download_source', 'entry_id', 'get_short_id', 'journal_ref', 'links', 'pdf_url', 'primary_category', 'published', 'summary', 'title', 'updated']\n","['Author', 'Link', 'MissingFieldError', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_from_feed_entry', '_get_default_filename', '_get_pdf_url', '_raw', '_substitute_domain', '_to_datetime', 'authors', 'categories', 'comment', 'doi', 'download_pdf', 'download_source', 'entry_id', 'get_short_id', 'journal_ref', 'links', 'pdf_url', 'primary_category', 'published', 'summary', 'title', 'updated']\n","['Author', 'Link', 'MissingFieldError', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_from_feed_entry', '_get_default_filename', '_get_pdf_url', '_raw', '_substitute_domain', '_to_datetime', 'authors', 'categories', 'comment', 'doi', 'download_pdf', 'download_source', 'entry_id', 'get_short_id', 'journal_ref', 'links', 'pdf_url', 'primary_category', 'published', 'summary', 'title', 'updated']\n","['Author', 'Link', 'MissingFieldError', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_from_feed_entry', '_get_default_filename', '_get_pdf_url', '_raw', '_substitute_domain', '_to_datetime', 'authors', 'categories', 'comment', 'doi', 'download_pdf', 'download_source', 'entry_id', 'get_short_id', 'journal_ref', 'links', 'pdf_url', 'primary_category', 'published', 'summary', 'title', 'updated']\n","['Author', 'Link', 'MissingFieldError', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_from_feed_entry', '_get_default_filename', '_get_pdf_url', '_raw', '_substitute_domain', '_to_datetime', 'authors', 'categories', 'comment', 'doi', 'download_pdf', 'download_source', 'entry_id', 'get_short_id', 'journal_ref', 'links', 'pdf_url', 'primary_category', 'published', 'summary', 'title', 'updated']\n","['Author', 'Link', 'MissingFieldError', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_from_feed_entry', '_get_default_filename', '_get_pdf_url', '_raw', '_substitute_domain', '_to_datetime', 'authors', 'categories', 'comment', 'doi', 'download_pdf', 'download_source', 'entry_id', 'get_short_id', 'journal_ref', 'links', 'pdf_url', 'primary_category', 'published', 'summary', 'title', 'updated']\n","['Author', 'Link', 'MissingFieldError', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_from_feed_entry', '_get_default_filename', '_get_pdf_url', '_raw', '_substitute_domain', '_to_datetime', 'authors', 'categories', 'comment', 'doi', 'download_pdf', 'download_source', 'entry_id', 'get_short_id', 'journal_ref', 'links', 'pdf_url', 'primary_category', 'published', 'summary', 'title', 'updated']\n","['Author', 'Link', 'MissingFieldError', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_from_feed_entry', '_get_default_filename', '_get_pdf_url', '_raw', '_substitute_domain', '_to_datetime', 'authors', 'categories', 'comment', 'doi', 'download_pdf', 'download_source', 'entry_id', 'get_short_id', 'journal_ref', 'links', 'pdf_url', 'primary_category', 'published', 'summary', 'title', 'updated']\n","['Author', 'Link', 'MissingFieldError', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_from_feed_entry', '_get_default_filename', '_get_pdf_url', '_raw', '_substitute_domain', '_to_datetime', 'authors', 'categories', 'comment', 'doi', 'download_pdf', 'download_source', 'entry_id', 'get_short_id', 'journal_ref', 'links', 'pdf_url', 'primary_category', 'published', 'summary', 'title', 'updated']\n","['Author', 'Link', 'MissingFieldError', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_from_feed_entry', '_get_default_filename', '_get_pdf_url', '_raw', '_substitute_domain', '_to_datetime', 'authors', 'categories', 'comment', 'doi', 'download_pdf', 'download_source', 'entry_id', 'get_short_id', 'journal_ref', 'links', 'pdf_url', 'primary_category', 'published', 'summary', 'title', 'updated']\n"]}]},{"cell_type":"code","source":["papers=[]\n","for result in search.results():\n","  papers.append(\n","      {\n","          \"published\":result.published,\n","          \"title\":result.title,\n","          \"abstract\":result.summary,\n","          \"categories\":result.categories\n","\n","      }\n","  )\n","\n","df=pd.DataFrame(papers)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"acNU9i_kiiti","executionInfo":{"status":"ok","timestamp":1754386810861,"user_tz":-345,"elapsed":242,"user":{"displayName":"Dinesh Tamang","userId":"12691506856444135406"}},"outputId":"d041c773-9e5b-4729-967b-c72677969c0e"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1717658952.py:2: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n","  for result in search.results():\n"]}]},{"cell_type":"code","source":["pd.set_option('display.max_colwidth',None)\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"LCu8nJWejziU","executionInfo":{"status":"ok","timestamp":1754386811058,"user_tz":-345,"elapsed":89,"user":{"displayName":"Dinesh Tamang","userId":"12691506856444135406"}},"outputId":"4f816e71-8cb7-4d89-95b5-760521330cf4"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                  published  \\\n","0 2025-08-04 17:59:38+00:00   \n","1 2025-08-04 17:58:22+00:00   \n","2 2025-08-04 17:43:22+00:00   \n","3 2025-08-04 17:33:41+00:00   \n","4 2025-08-04 17:33:36+00:00   \n","5 2025-08-04 17:25:55+00:00   \n","6 2025-08-04 17:25:36+00:00   \n","7 2025-08-04 17:23:14+00:00   \n","8 2025-08-04 17:23:00+00:00   \n","9 2025-08-04 17:20:50+00:00   \n","\n","                                                                                                                                     title  \\\n","0                                                                          MedVLThinker: Simple Baselines for Multimodal Medical Reasoning   \n","1                                                                         LOST: Low-rank and Sparse Pre-training for Large Language Models   \n","2                                                                                  Open Molecular Crystals 2025 (OMC25) Dataset and Models   \n","3                                                                         D2PPO: Diffusion Policy Policy Optimization with Dispersive Loss   \n","4                                                                                   CAK: Emergent Audio Effects from Minimal Deep Learning   \n","5                                               FastCSP: Accelerated Molecular Crystal Structure Prediction with Universal Model for Atoms   \n","6                                                   An Efficient Continuous-Time MILP for Integrated Aircraft Hangar Scheduling and Layout   \n","7                                             Anticipating Decoherence: a Predictive Framework for Enhancing Coherence in Quantum Emitters   \n","8                                                                                         Instance-Optimal Uniformity Testing and Tracking   \n","9  Actionable Counterfactual Explanations Using Bayesian Networks and Path Planning with Applications to Environmental Quality Improvement   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                abstract  \\\n","0                                              Large Reasoning Models (LRMs) have introduced a new paradigm in AI by\\nenabling models to ``think before responding\" via chain-of-thought reasoning.\\nHowever, the absence of open and reproducible recipes for building\\nreasoning-centric medical LMMs hinders community-wide research, analysis, and\\ncomparison. In this paper, we present MedVLThinker, a suite of simple yet\\nstrong baselines. Our fully open recipe consists of: (1) systematic data\\ncuration for both text-only and image-text medical data, filtered according to\\nvarying levels of reasoning difficulty, and (2) two training paradigms:\\nSupervised Fine-Tuning (SFT) on distilled reasoning traces and Reinforcement\\nLearning with Verifiable Rewards (RLVR) based on final answer correctness.\\nAcross extensive experiments on the Qwen2.5-VL model family (3B, 7B) and six\\nmedical QA benchmarks, we find that RLVR consistently and significantly\\noutperforms SFT. Additionally, under the RLVR framework, a key,\\ncounter-intuitive finding is that training on our curated text-only reasoning\\ndata provides a more substantial performance boost than training on multimodal\\nimage-text data. Our best open 7B model, trained using the RLVR recipe on\\ntext-only data, establishes a new state-of-the-art on existing public VQA\\nbenchmarks, surpassing all previous open-source medical LMMs. Furthermore,\\nscaling our model to 32B achieves performance on par with the proprietary\\nGPT-4o. We release all curated data, models, and code to provide the community\\nwith a strong, open foundation for future research in multimodal medical\\nreasoning.   \n","1  While large language models (LLMs) have achieved remarkable performance\\nacross a wide range of tasks, their massive scale incurs prohibitive\\ncomputational and memory costs for pre-training from scratch. Recent studies\\nhave investigated the use of low-rank parameterization as a means of reducing\\nmodel size and training cost. In this context, sparsity is often employed as a\\ncomplementary technique to recover important information lost in low-rank\\ncompression by capturing salient features in the residual space. However,\\nexisting approaches typically combine low-rank and sparse components in a\\nsimplistic or ad hoc manner, often resulting in undesirable performance\\ndegradation compared to full-rank training. In this paper, we propose\\n\\textbf{LO}w-rank and \\textbf{S}parse pre-\\textbf{T}raining (\\textbf{LOST}) for\\nLLMs, a novel method that ingeniously integrates low-rank and sparse structures\\nto enable effective training of LLMs from scratch under strict efficiency\\nconstraints. LOST applies singular value decomposition to weight matrices,\\npreserving the dominant low-rank components, while allocating the remaining\\nsingular values to construct channel-wise sparse components to complement the\\nexpressiveness of low-rank training. We evaluate LOST on LLM pretraining\\nranging from 60M to 7B parameters. Our experiments show that LOST achieves\\ncompetitive or superior performance compared to full-rank models, while\\nsignificantly reducing both memory and compute overhead. Moreover, Code is\\navailable at\\n\\href{https://github.com/JiaxiLi1/LOST-Low-rank-and-Sparse-Training-for-Large-Language-Models}{LOST\\nRepo}   \n","2                                                                                                                                                                                                                                                                                                                                                                                                                            The development of accurate and efficient machine learning models for\\npredicting the structure and properties of molecular crystals has been hindered\\nby the scarcity of publicly available datasets of structures with property\\nlabels. To address this challenge, we introduce the Open Molecular Crystals\\n2025 (OMC25) dataset, a collection of over 27 million molecular crystal\\nstructures containing 12 elements and up to 300 atoms in the unit cell. The\\ndataset was generated from dispersion-inclusive density functional theory (DFT)\\nrelaxation trajectories of over 230,000 randomly generated molecular crystal\\nstructures of around 50,000 organic molecules. OMC25 comprises diverse chemical\\ncompounds capable of forming different intermolecular interactions and a wide\\nrange of crystal packing motifs. We provide detailed information on the\\ndataset's construction, composition, structure, and properties. To demonstrate\\nthe quality and use cases of OMC25, we further trained and evaluated\\nstate-of-the-art open-source machine learning interatomic potentials. By making\\nthis dataset publicly available, we aim to accelerate the development of more\\naccurate and efficient machine learning models for molecular crystals.   \n","3                                                                                                                                                                                   Diffusion policies excel at robotic manipulation by naturally modeling\\nmultimodal action distributions in high-dimensional spaces. Nevertheless,\\ndiffusion policies suffer from diffusion representation collapse: semantically\\nsimilar observations are mapped to indistinguishable features, ultimately\\nimpairing their ability to handle subtle but critical variations required for\\ncomplex robotic manipulation. To address this problem, we propose D2PPO\\n(Diffusion Policy Policy Optimization with Dispersive Loss). D2PPO introduces\\ndispersive loss regularization that combats representation collapse by treating\\nall hidden representations within each batch as negative pairs. D2PPO compels\\nthe network to learn discriminative representations of similar observations,\\nthereby enabling the policy to identify subtle yet crucial differences\\nnecessary for precise manipulation. In evaluation, we find that early-layer\\nregularization benefits simple tasks, while late-layer regularization sharply\\nenhances performance on complex manipulation tasks. On RoboMimic benchmarks,\\nD2PPO achieves an average improvement of 22.7% in pre-training and 26.1% after\\nfine-tuning, setting new SOTA results. In comparison with SOTA, results of\\nreal-world experiments on a Franka Emika Panda robot show the excitingly high\\nsuccess rate of our method. The superiority of our method is especially evident\\nin complex tasks. Project page: https://guowei-zou.github.io/d2ppo/   \n","4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          We demonstrate that a single 3x3 convolutional kernel can produce emergent\\naudio effects when trained on 200 samples from a personalized corpus. We\\nachieve this through two key techniques: (1) Conditioning Aware Kernels (CAK),\\nwhere output = input + (learned_pattern x control), with a soft-gate mechanism\\nsupporting identity preservation at zero control; and (2) AuGAN (Audit GAN),\\nwhich reframes adversarial training from \"is this real?\" to \"did you apply the\\nrequested value?\" Rather than learning to generate or detect forgeries, our\\nnetworks cooperate to verify control application, discovering unique\\ntransformations. The learned kernel exhibits a diagonal structure creating\\nfrequency-dependent temporal shifts that are capable of producing musical\\neffects based on input characteristics. Our results show the potential of\\nadversarial training to discover audio transformations from minimal data,\\nenabling new approaches to effect design.   \n","5               Crystal Structure Prediction (CSP) of molecular crystals plays a central role\\nin applications, such as pharmaceuticals and organic electronics. CSP is\\nchallenging and computationally expensive due to the need to explore a large\\nsearch space with sufficient accuracy to capture energy differences of a few\\nkJ/mol between polymorphs. Dispersion-inclusive density functional theory (DFT)\\nprovides the required accuracy but its computational cost is impractical for a\\nlarge number of putative structures. We introduce FastCSP, an open-source,\\nhigh-throughput CSP workflow based on machine learning interatomic potentials\\n(MLIPs). FastCSP combines random structure generation using Genarris 3.0 with\\ngeometry relaxation and free energy calculations powered entirely by the\\nUniversal Model for Atoms (UMA) MLIP. We benchmark FastCSP on a curated set of\\n28 mostly rigid molecules, demonstrating that our workflow consistently\\ngenerates known experimental structures and ranks them within 5 kJ/mol per\\nmolecule of the global minimum. Our results demonstrate that universal MLIPs\\ncan be used across diverse compounds without requiring system-specific tuning.\\nMoreover, the speed and accuracy afforded by UMA eliminate the need for\\nclassical force fields in the early stages of CSP and for final re-ranking with\\nDFT. The open-source release of the entire FastCSP workflow significantly\\nlowers the barrier to accessing CSP. CSP results for a single system can be\\nobtained within hours on tens of modern GPUs, making high-throughput crystal\\nstructure prediction feasible for a broad range of scientific applications.   \n","6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Efficient management of aircraft maintenance hangars is a critical\\noperational challenge, involving complex, interdependent decisions regarding\\naircraft scheduling and spatial allocation. This paper introduces a novel\\ncontinuous-time mixed-integer linear programming (MILP) model to solve this\\nintegrated spatio-temporal problem. By treating time as a continuous variable,\\nour formulation overcomes the scalability limitations of traditional\\ndiscrete-time approaches. The performance of the exact model is benchmarked\\nagainst a constructive heuristic, and its practical applicability is\\ndemonstrated through a custom-built visualization dashboard. Computational\\nresults are compelling: the model solves instances with up to 25 aircraft to\\nproven optimality, often in mere seconds, and for large-scale cases of up to 40\\naircraft, delivers high-quality solutions within known optimality gaps. In all\\ntested scenarios, the resulting solutions consistently and significantly\\noutperform the heuristic, which highlights the framework's substantial economic\\nbenefits and provides valuable managerial insights into the trade-off between\\nsolution time and optimality.   \n","7                                                                                  Large-scale quantum systems require optical coherence between distant quantum\\ndevices, necessitating spectral indistinguishability. Scalable solid-state\\nplatforms offer promising routes to this goal. However, environmental\\ndisorders, including dephasing, spectral diffusion, and spin-bath interactions,\\ninfluence the emitters' spectra and deteriorate the coherence. Using\\nstatistical theory, we identify correlations in spectral diffusion from slowly\\nvarying environmental coupling, revealing predictable dynamics extendable to\\nother disorders. Importantly, this could enable the development of an\\nanticipatory framework for forecasting and decoherence engineering in remote\\nquantum emitters. To validate this framework, we demonstrate that a machine\\nlearning model trained on limited data can accurately forecast unseen spectral\\nbehavior. Realization of such a model on distinct quantum emitters could reduce\\nthe spectral shift by factors $\\approx$ 2.1 to 15.8, depending on emitter\\nstability, compared to no prediction. This work presents, for the first time,\\nthe application of anticipatory systems and replica theory to quantum\\ntechnology, along with the first experimental demonstration of internal\\nprediction that generalizes across multiple quantum emitters. These results\\npave the way for real-time decoherence engineering in scalable quantum systems.\\nSuch capability could lead to enhanced optical coherence and multi-emitter\\nsynchronization, with broad implications for quantum communication,\\ncomputation, imaging, and sensing.   \n","8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       In the uniformity testing task, an algorithm is provided with samples from an\\nunknown probability distribution over a (known) finite domain, and must decide\\nwhether it is the uniform distribution, or, alternatively, if its total\\nvariation distance from uniform exceeds some input distance parameter. This\\nquestion has received a significant amount of interest and its complexity is,\\nby now, fully settled. Yet, we argue that it fails to capture many scenarios of\\ninterest, and that its very definition as a gap problem in terms of a\\nprespecified distance may lead to suboptimal performance.\\n  To address these shortcomings, we introduce the problem of uniformity\\ntracking, whereby an algorithm is required to detect deviations from uniformity\\n(however they may manifest themselves) using as few samples as possible, and be\\ncompetitive against an optimal algorithm knowing the distribution profile in\\nhindsight. Our main contribution is a\\n$\\operatorname{polylog}(\\operatorname{opt})$-competitive uniformity tracking\\nalgorithm. We obtain this result by leveraging new structural results on\\nPoisson mixtures, which we believe to be of independent interest.   \n","9        Counterfactual explanations study what should have changed in order to get an\\nalternative result, enabling end-users to understand machine learning\\nmechanisms with counterexamples. Actionability is defined as the ability to\\ntransform the original case to be explained into a counterfactual one. We\\ndevelop a method for actionable counterfactual explanations that, unlike\\npredecessors, does not directly leverage training data. Rather, data is only\\nused to learn a density estimator, creating a search landscape in which to\\napply path planning algorithms to solve the problem and masking the endogenous\\ndata, which can be sensitive or private. We put special focus on estimating the\\ndata density using Bayesian networks, demonstrating how their enhanced\\ninterpretability is useful in high-stakes scenarios in which fairness is\\nraising concern. Using a synthetic benchmark comprised of 15 datasets, our\\nproposal finds more actionable and simpler counterfactuals than the current\\nstate-of-the-art algorithms. We also test our algorithm with a real-world\\nEnvironmental Protection Agency dataset, facilitating a more efficient and\\nequitable study of policies to improve the quality of life in United States of\\nAmerica counties. Our proposal captures the interaction of variables, ensuring\\nequity in decisions, as policies to improve certain domains of study (air,\\nwater quality, etc.) can be detrimental in others. In particular, the\\nsociodemographic domain is often involved, where we find important variables\\nrelated to the ongoing housing crisis that can potentially have a severe\\nnegative impact on communities.   \n","\n","                                                           categories  \n","0                                                             [cs.CV]  \n","1                                                             [cs.LG]  \n","2                                                   [physics.chem-ph]  \n","3                                                             [cs.AI]  \n","4                                             [cs.LG, cs.SD, eess.AS]  \n","5                                            [physics.chem-ph, cs.LG]  \n","6  [math.OC, cs.AI, cs.CE, 90C11 (Primary), 90B35, 90C27 (Secondary)]  \n","7                                                          [quant-ph]  \n","8                                                      [cs.DS, cs.LG]  \n","9                                                      [cs.AI, cs.LG]  "],"text/html":["\n","  <div id=\"df-9474758c-7ee9-482d-b5f2-116df559d6bf\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>published</th>\n","      <th>title</th>\n","      <th>abstract</th>\n","      <th>categories</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2025-08-04 17:59:38+00:00</td>\n","      <td>MedVLThinker: Simple Baselines for Multimodal Medical Reasoning</td>\n","      <td>Large Reasoning Models (LRMs) have introduced a new paradigm in AI by\\nenabling models to ``think before responding\" via chain-of-thought reasoning.\\nHowever, the absence of open and reproducible recipes for building\\nreasoning-centric medical LMMs hinders community-wide research, analysis, and\\ncomparison. In this paper, we present MedVLThinker, a suite of simple yet\\nstrong baselines. Our fully open recipe consists of: (1) systematic data\\ncuration for both text-only and image-text medical data, filtered according to\\nvarying levels of reasoning difficulty, and (2) two training paradigms:\\nSupervised Fine-Tuning (SFT) on distilled reasoning traces and Reinforcement\\nLearning with Verifiable Rewards (RLVR) based on final answer correctness.\\nAcross extensive experiments on the Qwen2.5-VL model family (3B, 7B) and six\\nmedical QA benchmarks, we find that RLVR consistently and significantly\\noutperforms SFT. Additionally, under the RLVR framework, a key,\\ncounter-intuitive finding is that training on our curated text-only reasoning\\ndata provides a more substantial performance boost than training on multimodal\\nimage-text data. Our best open 7B model, trained using the RLVR recipe on\\ntext-only data, establishes a new state-of-the-art on existing public VQA\\nbenchmarks, surpassing all previous open-source medical LMMs. Furthermore,\\nscaling our model to 32B achieves performance on par with the proprietary\\nGPT-4o. We release all curated data, models, and code to provide the community\\nwith a strong, open foundation for future research in multimodal medical\\nreasoning.</td>\n","      <td>[cs.CV]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2025-08-04 17:58:22+00:00</td>\n","      <td>LOST: Low-rank and Sparse Pre-training for Large Language Models</td>\n","      <td>While large language models (LLMs) have achieved remarkable performance\\nacross a wide range of tasks, their massive scale incurs prohibitive\\ncomputational and memory costs for pre-training from scratch. Recent studies\\nhave investigated the use of low-rank parameterization as a means of reducing\\nmodel size and training cost. In this context, sparsity is often employed as a\\ncomplementary technique to recover important information lost in low-rank\\ncompression by capturing salient features in the residual space. However,\\nexisting approaches typically combine low-rank and sparse components in a\\nsimplistic or ad hoc manner, often resulting in undesirable performance\\ndegradation compared to full-rank training. In this paper, we propose\\n\\textbf{LO}w-rank and \\textbf{S}parse pre-\\textbf{T}raining (\\textbf{LOST}) for\\nLLMs, a novel method that ingeniously integrates low-rank and sparse structures\\nto enable effective training of LLMs from scratch under strict efficiency\\nconstraints. LOST applies singular value decomposition to weight matrices,\\npreserving the dominant low-rank components, while allocating the remaining\\nsingular values to construct channel-wise sparse components to complement the\\nexpressiveness of low-rank training. We evaluate LOST on LLM pretraining\\nranging from 60M to 7B parameters. Our experiments show that LOST achieves\\ncompetitive or superior performance compared to full-rank models, while\\nsignificantly reducing both memory and compute overhead. Moreover, Code is\\navailable at\\n\\href{https://github.com/JiaxiLi1/LOST-Low-rank-and-Sparse-Training-for-Large-Language-Models}{LOST\\nRepo}</td>\n","      <td>[cs.LG]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2025-08-04 17:43:22+00:00</td>\n","      <td>Open Molecular Crystals 2025 (OMC25) Dataset and Models</td>\n","      <td>The development of accurate and efficient machine learning models for\\npredicting the structure and properties of molecular crystals has been hindered\\nby the scarcity of publicly available datasets of structures with property\\nlabels. To address this challenge, we introduce the Open Molecular Crystals\\n2025 (OMC25) dataset, a collection of over 27 million molecular crystal\\nstructures containing 12 elements and up to 300 atoms in the unit cell. The\\ndataset was generated from dispersion-inclusive density functional theory (DFT)\\nrelaxation trajectories of over 230,000 randomly generated molecular crystal\\nstructures of around 50,000 organic molecules. OMC25 comprises diverse chemical\\ncompounds capable of forming different intermolecular interactions and a wide\\nrange of crystal packing motifs. We provide detailed information on the\\ndataset's construction, composition, structure, and properties. To demonstrate\\nthe quality and use cases of OMC25, we further trained and evaluated\\nstate-of-the-art open-source machine learning interatomic potentials. By making\\nthis dataset publicly available, we aim to accelerate the development of more\\naccurate and efficient machine learning models for molecular crystals.</td>\n","      <td>[physics.chem-ph]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2025-08-04 17:33:41+00:00</td>\n","      <td>D2PPO: Diffusion Policy Policy Optimization with Dispersive Loss</td>\n","      <td>Diffusion policies excel at robotic manipulation by naturally modeling\\nmultimodal action distributions in high-dimensional spaces. Nevertheless,\\ndiffusion policies suffer from diffusion representation collapse: semantically\\nsimilar observations are mapped to indistinguishable features, ultimately\\nimpairing their ability to handle subtle but critical variations required for\\ncomplex robotic manipulation. To address this problem, we propose D2PPO\\n(Diffusion Policy Policy Optimization with Dispersive Loss). D2PPO introduces\\ndispersive loss regularization that combats representation collapse by treating\\nall hidden representations within each batch as negative pairs. D2PPO compels\\nthe network to learn discriminative representations of similar observations,\\nthereby enabling the policy to identify subtle yet crucial differences\\nnecessary for precise manipulation. In evaluation, we find that early-layer\\nregularization benefits simple tasks, while late-layer regularization sharply\\nenhances performance on complex manipulation tasks. On RoboMimic benchmarks,\\nD2PPO achieves an average improvement of 22.7% in pre-training and 26.1% after\\nfine-tuning, setting new SOTA results. In comparison with SOTA, results of\\nreal-world experiments on a Franka Emika Panda robot show the excitingly high\\nsuccess rate of our method. The superiority of our method is especially evident\\nin complex tasks. Project page: https://guowei-zou.github.io/d2ppo/</td>\n","      <td>[cs.AI]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2025-08-04 17:33:36+00:00</td>\n","      <td>CAK: Emergent Audio Effects from Minimal Deep Learning</td>\n","      <td>We demonstrate that a single 3x3 convolutional kernel can produce emergent\\naudio effects when trained on 200 samples from a personalized corpus. We\\nachieve this through two key techniques: (1) Conditioning Aware Kernels (CAK),\\nwhere output = input + (learned_pattern x control), with a soft-gate mechanism\\nsupporting identity preservation at zero control; and (2) AuGAN (Audit GAN),\\nwhich reframes adversarial training from \"is this real?\" to \"did you apply the\\nrequested value?\" Rather than learning to generate or detect forgeries, our\\nnetworks cooperate to verify control application, discovering unique\\ntransformations. The learned kernel exhibits a diagonal structure creating\\nfrequency-dependent temporal shifts that are capable of producing musical\\neffects based on input characteristics. Our results show the potential of\\nadversarial training to discover audio transformations from minimal data,\\nenabling new approaches to effect design.</td>\n","      <td>[cs.LG, cs.SD, eess.AS]</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2025-08-04 17:25:55+00:00</td>\n","      <td>FastCSP: Accelerated Molecular Crystal Structure Prediction with Universal Model for Atoms</td>\n","      <td>Crystal Structure Prediction (CSP) of molecular crystals plays a central role\\nin applications, such as pharmaceuticals and organic electronics. CSP is\\nchallenging and computationally expensive due to the need to explore a large\\nsearch space with sufficient accuracy to capture energy differences of a few\\nkJ/mol between polymorphs. Dispersion-inclusive density functional theory (DFT)\\nprovides the required accuracy but its computational cost is impractical for a\\nlarge number of putative structures. We introduce FastCSP, an open-source,\\nhigh-throughput CSP workflow based on machine learning interatomic potentials\\n(MLIPs). FastCSP combines random structure generation using Genarris 3.0 with\\ngeometry relaxation and free energy calculations powered entirely by the\\nUniversal Model for Atoms (UMA) MLIP. We benchmark FastCSP on a curated set of\\n28 mostly rigid molecules, demonstrating that our workflow consistently\\ngenerates known experimental structures and ranks them within 5 kJ/mol per\\nmolecule of the global minimum. Our results demonstrate that universal MLIPs\\ncan be used across diverse compounds without requiring system-specific tuning.\\nMoreover, the speed and accuracy afforded by UMA eliminate the need for\\nclassical force fields in the early stages of CSP and for final re-ranking with\\nDFT. The open-source release of the entire FastCSP workflow significantly\\nlowers the barrier to accessing CSP. CSP results for a single system can be\\nobtained within hours on tens of modern GPUs, making high-throughput crystal\\nstructure prediction feasible for a broad range of scientific applications.</td>\n","      <td>[physics.chem-ph, cs.LG]</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2025-08-04 17:25:36+00:00</td>\n","      <td>An Efficient Continuous-Time MILP for Integrated Aircraft Hangar Scheduling and Layout</td>\n","      <td>Efficient management of aircraft maintenance hangars is a critical\\noperational challenge, involving complex, interdependent decisions regarding\\naircraft scheduling and spatial allocation. This paper introduces a novel\\ncontinuous-time mixed-integer linear programming (MILP) model to solve this\\nintegrated spatio-temporal problem. By treating time as a continuous variable,\\nour formulation overcomes the scalability limitations of traditional\\ndiscrete-time approaches. The performance of the exact model is benchmarked\\nagainst a constructive heuristic, and its practical applicability is\\ndemonstrated through a custom-built visualization dashboard. Computational\\nresults are compelling: the model solves instances with up to 25 aircraft to\\nproven optimality, often in mere seconds, and for large-scale cases of up to 40\\naircraft, delivers high-quality solutions within known optimality gaps. In all\\ntested scenarios, the resulting solutions consistently and significantly\\noutperform the heuristic, which highlights the framework's substantial economic\\nbenefits and provides valuable managerial insights into the trade-off between\\nsolution time and optimality.</td>\n","      <td>[math.OC, cs.AI, cs.CE, 90C11 (Primary), 90B35, 90C27 (Secondary)]</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>2025-08-04 17:23:14+00:00</td>\n","      <td>Anticipating Decoherence: a Predictive Framework for Enhancing Coherence in Quantum Emitters</td>\n","      <td>Large-scale quantum systems require optical coherence between distant quantum\\ndevices, necessitating spectral indistinguishability. Scalable solid-state\\nplatforms offer promising routes to this goal. However, environmental\\ndisorders, including dephasing, spectral diffusion, and spin-bath interactions,\\ninfluence the emitters' spectra and deteriorate the coherence. Using\\nstatistical theory, we identify correlations in spectral diffusion from slowly\\nvarying environmental coupling, revealing predictable dynamics extendable to\\nother disorders. Importantly, this could enable the development of an\\nanticipatory framework for forecasting and decoherence engineering in remote\\nquantum emitters. To validate this framework, we demonstrate that a machine\\nlearning model trained on limited data can accurately forecast unseen spectral\\nbehavior. Realization of such a model on distinct quantum emitters could reduce\\nthe spectral shift by factors $\\approx$ 2.1 to 15.8, depending on emitter\\nstability, compared to no prediction. This work presents, for the first time,\\nthe application of anticipatory systems and replica theory to quantum\\ntechnology, along with the first experimental demonstration of internal\\nprediction that generalizes across multiple quantum emitters. These results\\npave the way for real-time decoherence engineering in scalable quantum systems.\\nSuch capability could lead to enhanced optical coherence and multi-emitter\\nsynchronization, with broad implications for quantum communication,\\ncomputation, imaging, and sensing.</td>\n","      <td>[quant-ph]</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2025-08-04 17:23:00+00:00</td>\n","      <td>Instance-Optimal Uniformity Testing and Tracking</td>\n","      <td>In the uniformity testing task, an algorithm is provided with samples from an\\nunknown probability distribution over a (known) finite domain, and must decide\\nwhether it is the uniform distribution, or, alternatively, if its total\\nvariation distance from uniform exceeds some input distance parameter. This\\nquestion has received a significant amount of interest and its complexity is,\\nby now, fully settled. Yet, we argue that it fails to capture many scenarios of\\ninterest, and that its very definition as a gap problem in terms of a\\nprespecified distance may lead to suboptimal performance.\\n  To address these shortcomings, we introduce the problem of uniformity\\ntracking, whereby an algorithm is required to detect deviations from uniformity\\n(however they may manifest themselves) using as few samples as possible, and be\\ncompetitive against an optimal algorithm knowing the distribution profile in\\nhindsight. Our main contribution is a\\n$\\operatorname{polylog}(\\operatorname{opt})$-competitive uniformity tracking\\nalgorithm. We obtain this result by leveraging new structural results on\\nPoisson mixtures, which we believe to be of independent interest.</td>\n","      <td>[cs.DS, cs.LG]</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>2025-08-04 17:20:50+00:00</td>\n","      <td>Actionable Counterfactual Explanations Using Bayesian Networks and Path Planning with Applications to Environmental Quality Improvement</td>\n","      <td>Counterfactual explanations study what should have changed in order to get an\\nalternative result, enabling end-users to understand machine learning\\nmechanisms with counterexamples. Actionability is defined as the ability to\\ntransform the original case to be explained into a counterfactual one. We\\ndevelop a method for actionable counterfactual explanations that, unlike\\npredecessors, does not directly leverage training data. Rather, data is only\\nused to learn a density estimator, creating a search landscape in which to\\napply path planning algorithms to solve the problem and masking the endogenous\\ndata, which can be sensitive or private. We put special focus on estimating the\\ndata density using Bayesian networks, demonstrating how their enhanced\\ninterpretability is useful in high-stakes scenarios in which fairness is\\nraising concern. Using a synthetic benchmark comprised of 15 datasets, our\\nproposal finds more actionable and simpler counterfactuals than the current\\nstate-of-the-art algorithms. We also test our algorithm with a real-world\\nEnvironmental Protection Agency dataset, facilitating a more efficient and\\nequitable study of policies to improve the quality of life in United States of\\nAmerica counties. Our proposal captures the interaction of variables, ensuring\\nequity in decisions, as policies to improve certain domains of study (air,\\nwater quality, etc.) can be detrimental in others. In particular, the\\nsociodemographic domain is often involved, where we find important variables\\nrelated to the ongoing housing crisis that can potentially have a severe\\nnegative impact on communities.</td>\n","      <td>[cs.AI, cs.LG]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9474758c-7ee9-482d-b5f2-116df559d6bf')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9474758c-7ee9-482d-b5f2-116df559d6bf button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9474758c-7ee9-482d-b5f2-116df559d6bf');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-ec42d9bc-bd53-41d5-bcec-3f8e69f62516\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ec42d9bc-bd53-41d5-bcec-3f8e69f62516')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-ec42d9bc-bd53-41d5-bcec-3f8e69f62516 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_40656506-7f46-486f-82a5-c73e4f4351dc\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_40656506-7f46-486f-82a5-c73e4f4351dc button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"published\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-08-04 17:20:50+00:00\",\n        \"max\": \"2025-08-04 17:59:38+00:00\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"2025-08-04 17:23:00+00:00\",\n          \"2025-08-04 17:58:22+00:00\",\n          \"2025-08-04 17:25:55+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Instance-Optimal Uniformity Testing and Tracking\",\n          \"LOST: Low-rank and Sparse Pre-training for Large Language Models\",\n          \"FastCSP: Accelerated Molecular Crystal Structure Prediction with Universal Model for Atoms\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"In the uniformity testing task, an algorithm is provided with samples from an\\nunknown probability distribution over a (known) finite domain, and must decide\\nwhether it is the uniform distribution, or, alternatively, if its total\\nvariation distance from uniform exceeds some input distance parameter. This\\nquestion has received a significant amount of interest and its complexity is,\\nby now, fully settled. Yet, we argue that it fails to capture many scenarios of\\ninterest, and that its very definition as a gap problem in terms of a\\nprespecified distance may lead to suboptimal performance.\\n  To address these shortcomings, we introduce the problem of uniformity\\ntracking, whereby an algorithm is required to detect deviations from uniformity\\n(however they may manifest themselves) using as few samples as possible, and be\\ncompetitive against an optimal algorithm knowing the distribution profile in\\nhindsight. Our main contribution is a\\n$\\\\operatorname{polylog}(\\\\operatorname{opt})$-competitive uniformity tracking\\nalgorithm. We obtain this result by leveraging new structural results on\\nPoisson mixtures, which we believe to be of independent interest.\",\n          \"While large language models (LLMs) have achieved remarkable performance\\nacross a wide range of tasks, their massive scale incurs prohibitive\\ncomputational and memory costs for pre-training from scratch. Recent studies\\nhave investigated the use of low-rank parameterization as a means of reducing\\nmodel size and training cost. In this context, sparsity is often employed as a\\ncomplementary technique to recover important information lost in low-rank\\ncompression by capturing salient features in the residual space. However,\\nexisting approaches typically combine low-rank and sparse components in a\\nsimplistic or ad hoc manner, often resulting in undesirable performance\\ndegradation compared to full-rank training. In this paper, we propose\\n\\\\textbf{LO}w-rank and \\\\textbf{S}parse pre-\\\\textbf{T}raining (\\\\textbf{LOST}) for\\nLLMs, a novel method that ingeniously integrates low-rank and sparse structures\\nto enable effective training of LLMs from scratch under strict efficiency\\nconstraints. LOST applies singular value decomposition to weight matrices,\\npreserving the dominant low-rank components, while allocating the remaining\\nsingular values to construct channel-wise sparse components to complement the\\nexpressiveness of low-rank training. We evaluate LOST on LLM pretraining\\nranging from 60M to 7B parameters. Our experiments show that LOST achieves\\ncompetitive or superior performance compared to full-rank models, while\\nsignificantly reducing both memory and compute overhead. Moreover, Code is\\navailable at\\n\\\\href{https://github.com/JiaxiLi1/LOST-Low-rank-and-Sparse-Training-for-Large-Language-Models}{LOST\\nRepo}\",\n          \"Crystal Structure Prediction (CSP) of molecular crystals plays a central role\\nin applications, such as pharmaceuticals and organic electronics. CSP is\\nchallenging and computationally expensive due to the need to explore a large\\nsearch space with sufficient accuracy to capture energy differences of a few\\nkJ/mol between polymorphs. Dispersion-inclusive density functional theory (DFT)\\nprovides the required accuracy but its computational cost is impractical for a\\nlarge number of putative structures. We introduce FastCSP, an open-source,\\nhigh-throughput CSP workflow based on machine learning interatomic potentials\\n(MLIPs). FastCSP combines random structure generation using Genarris 3.0 with\\ngeometry relaxation and free energy calculations powered entirely by the\\nUniversal Model for Atoms (UMA) MLIP. We benchmark FastCSP on a curated set of\\n28 mostly rigid molecules, demonstrating that our workflow consistently\\ngenerates known experimental structures and ranks them within 5 kJ/mol per\\nmolecule of the global minimum. Our results demonstrate that universal MLIPs\\ncan be used across diverse compounds without requiring system-specific tuning.\\nMoreover, the speed and accuracy afforded by UMA eliminate the need for\\nclassical force fields in the early stages of CSP and for final re-ranking with\\nDFT. The open-source release of the entire FastCSP workflow significantly\\nlowers the barrier to accessing CSP. CSP results for a single system can be\\nobtained within hours on tens of modern GPUs, making high-throughput crystal\\nstructure prediction feasible for a broad range of scientific applications.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"categories\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["summarizer=pipeline(task=\"summarization\",model=\"facebook/bart-large-cnn\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2QwvqtfNlS-y","executionInfo":{"status":"ok","timestamp":1754386815321,"user_tz":-345,"elapsed":4276,"user":{"displayName":"Dinesh Tamang","userId":"12691506856444135406"}},"outputId":"9a809058-685e-4b14-c6ab-b450d0ad52c1"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cpu\n"]}]},{"cell_type":"code","source":["abstract=df[\"abstract\"]\n","abstract"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"83aPZxfam9H-","executionInfo":{"status":"ok","timestamp":1754387258806,"user_tz":-345,"elapsed":25,"user":{"displayName":"Dinesh Tamang","userId":"12691506856444135406"}},"outputId":"85c84a89-1483-48db-8256-d8fde0217c3b"},"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0                                                Large Reasoning Models (LRMs) have introduced a new paradigm in AI by\\nenabling models to ``think before responding\" via chain-of-thought reasoning.\\nHowever, the absence of open and reproducible recipes for building\\nreasoning-centric medical LMMs hinders community-wide research, analysis, and\\ncomparison. In this paper, we present MedVLThinker, a suite of simple yet\\nstrong baselines. Our fully open recipe consists of: (1) systematic data\\ncuration for both text-only and image-text medical data, filtered according to\\nvarying levels of reasoning difficulty, and (2) two training paradigms:\\nSupervised Fine-Tuning (SFT) on distilled reasoning traces and Reinforcement\\nLearning with Verifiable Rewards (RLVR) based on final answer correctness.\\nAcross extensive experiments on the Qwen2.5-VL model family (3B, 7B) and six\\nmedical QA benchmarks, we find that RLVR consistently and significantly\\noutperforms SFT. Additionally, under the RLVR framework, a key,\\ncounter-intuitive finding is that training on our curated text-only reasoning\\ndata provides a more substantial performance boost than training on multimodal\\nimage-text data. Our best open 7B model, trained using the RLVR recipe on\\ntext-only data, establishes a new state-of-the-art on existing public VQA\\nbenchmarks, surpassing all previous open-source medical LMMs. Furthermore,\\nscaling our model to 32B achieves performance on par with the proprietary\\nGPT-4o. We release all curated data, models, and code to provide the community\\nwith a strong, open foundation for future research in multimodal medical\\nreasoning.\n","1    While large language models (LLMs) have achieved remarkable performance\\nacross a wide range of tasks, their massive scale incurs prohibitive\\ncomputational and memory costs for pre-training from scratch. Recent studies\\nhave investigated the use of low-rank parameterization as a means of reducing\\nmodel size and training cost. In this context, sparsity is often employed as a\\ncomplementary technique to recover important information lost in low-rank\\ncompression by capturing salient features in the residual space. However,\\nexisting approaches typically combine low-rank and sparse components in a\\nsimplistic or ad hoc manner, often resulting in undesirable performance\\ndegradation compared to full-rank training. In this paper, we propose\\n\\textbf{LO}w-rank and \\textbf{S}parse pre-\\textbf{T}raining (\\textbf{LOST}) for\\nLLMs, a novel method that ingeniously integrates low-rank and sparse structures\\nto enable effective training of LLMs from scratch under strict efficiency\\nconstraints. LOST applies singular value decomposition to weight matrices,\\npreserving the dominant low-rank components, while allocating the remaining\\nsingular values to construct channel-wise sparse components to complement the\\nexpressiveness of low-rank training. We evaluate LOST on LLM pretraining\\nranging from 60M to 7B parameters. Our experiments show that LOST achieves\\ncompetitive or superior performance compared to full-rank models, while\\nsignificantly reducing both memory and compute overhead. Moreover, Code is\\navailable at\\n\\href{https://github.com/JiaxiLi1/LOST-Low-rank-and-Sparse-Training-for-Large-Language-Models}{LOST\\nRepo}\n","2                                                                                                                                                                                                                                                                                                                                                                                                                              The development of accurate and efficient machine learning models for\\npredicting the structure and properties of molecular crystals has been hindered\\nby the scarcity of publicly available datasets of structures with property\\nlabels. To address this challenge, we introduce the Open Molecular Crystals\\n2025 (OMC25) dataset, a collection of over 27 million molecular crystal\\nstructures containing 12 elements and up to 300 atoms in the unit cell. The\\ndataset was generated from dispersion-inclusive density functional theory (DFT)\\nrelaxation trajectories of over 230,000 randomly generated molecular crystal\\nstructures of around 50,000 organic molecules. OMC25 comprises diverse chemical\\ncompounds capable of forming different intermolecular interactions and a wide\\nrange of crystal packing motifs. We provide detailed information on the\\ndataset's construction, composition, structure, and properties. To demonstrate\\nthe quality and use cases of OMC25, we further trained and evaluated\\nstate-of-the-art open-source machine learning interatomic potentials. By making\\nthis dataset publicly available, we aim to accelerate the development of more\\naccurate and efficient machine learning models for molecular crystals.\n","3                                                                                                                                                                                     Diffusion policies excel at robotic manipulation by naturally modeling\\nmultimodal action distributions in high-dimensional spaces. Nevertheless,\\ndiffusion policies suffer from diffusion representation collapse: semantically\\nsimilar observations are mapped to indistinguishable features, ultimately\\nimpairing their ability to handle subtle but critical variations required for\\ncomplex robotic manipulation. To address this problem, we propose D2PPO\\n(Diffusion Policy Policy Optimization with Dispersive Loss). D2PPO introduces\\ndispersive loss regularization that combats representation collapse by treating\\nall hidden representations within each batch as negative pairs. D2PPO compels\\nthe network to learn discriminative representations of similar observations,\\nthereby enabling the policy to identify subtle yet crucial differences\\nnecessary for precise manipulation. In evaluation, we find that early-layer\\nregularization benefits simple tasks, while late-layer regularization sharply\\nenhances performance on complex manipulation tasks. On RoboMimic benchmarks,\\nD2PPO achieves an average improvement of 22.7% in pre-training and 26.1% after\\nfine-tuning, setting new SOTA results. In comparison with SOTA, results of\\nreal-world experiments on a Franka Emika Panda robot show the excitingly high\\nsuccess rate of our method. The superiority of our method is especially evident\\nin complex tasks. Project page: https://guowei-zou.github.io/d2ppo/\n","4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            We demonstrate that a single 3x3 convolutional kernel can produce emergent\\naudio effects when trained on 200 samples from a personalized corpus. We\\nachieve this through two key techniques: (1) Conditioning Aware Kernels (CAK),\\nwhere output = input + (learned_pattern x control), with a soft-gate mechanism\\nsupporting identity preservation at zero control; and (2) AuGAN (Audit GAN),\\nwhich reframes adversarial training from \"is this real?\" to \"did you apply the\\nrequested value?\" Rather than learning to generate or detect forgeries, our\\nnetworks cooperate to verify control application, discovering unique\\ntransformations. The learned kernel exhibits a diagonal structure creating\\nfrequency-dependent temporal shifts that are capable of producing musical\\neffects based on input characteristics. Our results show the potential of\\nadversarial training to discover audio transformations from minimal data,\\nenabling new approaches to effect design.\n","5                 Crystal Structure Prediction (CSP) of molecular crystals plays a central role\\nin applications, such as pharmaceuticals and organic electronics. CSP is\\nchallenging and computationally expensive due to the need to explore a large\\nsearch space with sufficient accuracy to capture energy differences of a few\\nkJ/mol between polymorphs. Dispersion-inclusive density functional theory (DFT)\\nprovides the required accuracy but its computational cost is impractical for a\\nlarge number of putative structures. We introduce FastCSP, an open-source,\\nhigh-throughput CSP workflow based on machine learning interatomic potentials\\n(MLIPs). FastCSP combines random structure generation using Genarris 3.0 with\\ngeometry relaxation and free energy calculations powered entirely by the\\nUniversal Model for Atoms (UMA) MLIP. We benchmark FastCSP on a curated set of\\n28 mostly rigid molecules, demonstrating that our workflow consistently\\ngenerates known experimental structures and ranks them within 5 kJ/mol per\\nmolecule of the global minimum. Our results demonstrate that universal MLIPs\\ncan be used across diverse compounds without requiring system-specific tuning.\\nMoreover, the speed and accuracy afforded by UMA eliminate the need for\\nclassical force fields in the early stages of CSP and for final re-ranking with\\nDFT. The open-source release of the entire FastCSP workflow significantly\\nlowers the barrier to accessing CSP. CSP results for a single system can be\\nobtained within hours on tens of modern GPUs, making high-throughput crystal\\nstructure prediction feasible for a broad range of scientific applications.\n","6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Efficient management of aircraft maintenance hangars is a critical\\noperational challenge, involving complex, interdependent decisions regarding\\naircraft scheduling and spatial allocation. This paper introduces a novel\\ncontinuous-time mixed-integer linear programming (MILP) model to solve this\\nintegrated spatio-temporal problem. By treating time as a continuous variable,\\nour formulation overcomes the scalability limitations of traditional\\ndiscrete-time approaches. The performance of the exact model is benchmarked\\nagainst a constructive heuristic, and its practical applicability is\\ndemonstrated through a custom-built visualization dashboard. Computational\\nresults are compelling: the model solves instances with up to 25 aircraft to\\nproven optimality, often in mere seconds, and for large-scale cases of up to 40\\naircraft, delivers high-quality solutions within known optimality gaps. In all\\ntested scenarios, the resulting solutions consistently and significantly\\noutperform the heuristic, which highlights the framework's substantial economic\\nbenefits and provides valuable managerial insights into the trade-off between\\nsolution time and optimality.\n","7                                                                                    Large-scale quantum systems require optical coherence between distant quantum\\ndevices, necessitating spectral indistinguishability. Scalable solid-state\\nplatforms offer promising routes to this goal. However, environmental\\ndisorders, including dephasing, spectral diffusion, and spin-bath interactions,\\ninfluence the emitters' spectra and deteriorate the coherence. Using\\nstatistical theory, we identify correlations in spectral diffusion from slowly\\nvarying environmental coupling, revealing predictable dynamics extendable to\\nother disorders. Importantly, this could enable the development of an\\nanticipatory framework for forecasting and decoherence engineering in remote\\nquantum emitters. To validate this framework, we demonstrate that a machine\\nlearning model trained on limited data can accurately forecast unseen spectral\\nbehavior. Realization of such a model on distinct quantum emitters could reduce\\nthe spectral shift by factors $\\approx$ 2.1 to 15.8, depending on emitter\\nstability, compared to no prediction. This work presents, for the first time,\\nthe application of anticipatory systems and replica theory to quantum\\ntechnology, along with the first experimental demonstration of internal\\nprediction that generalizes across multiple quantum emitters. These results\\npave the way for real-time decoherence engineering in scalable quantum systems.\\nSuch capability could lead to enhanced optical coherence and multi-emitter\\nsynchronization, with broad implications for quantum communication,\\ncomputation, imaging, and sensing.\n","8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         In the uniformity testing task, an algorithm is provided with samples from an\\nunknown probability distribution over a (known) finite domain, and must decide\\nwhether it is the uniform distribution, or, alternatively, if its total\\nvariation distance from uniform exceeds some input distance parameter. This\\nquestion has received a significant amount of interest and its complexity is,\\nby now, fully settled. Yet, we argue that it fails to capture many scenarios of\\ninterest, and that its very definition as a gap problem in terms of a\\nprespecified distance may lead to suboptimal performance.\\n  To address these shortcomings, we introduce the problem of uniformity\\ntracking, whereby an algorithm is required to detect deviations from uniformity\\n(however they may manifest themselves) using as few samples as possible, and be\\ncompetitive against an optimal algorithm knowing the distribution profile in\\nhindsight. Our main contribution is a\\n$\\operatorname{polylog}(\\operatorname{opt})$-competitive uniformity tracking\\nalgorithm. We obtain this result by leveraging new structural results on\\nPoisson mixtures, which we believe to be of independent interest.\n","9          Counterfactual explanations study what should have changed in order to get an\\nalternative result, enabling end-users to understand machine learning\\nmechanisms with counterexamples. Actionability is defined as the ability to\\ntransform the original case to be explained into a counterfactual one. We\\ndevelop a method for actionable counterfactual explanations that, unlike\\npredecessors, does not directly leverage training data. Rather, data is only\\nused to learn a density estimator, creating a search landscape in which to\\napply path planning algorithms to solve the problem and masking the endogenous\\ndata, which can be sensitive or private. We put special focus on estimating the\\ndata density using Bayesian networks, demonstrating how their enhanced\\ninterpretability is useful in high-stakes scenarios in which fairness is\\nraising concern. Using a synthetic benchmark comprised of 15 datasets, our\\nproposal finds more actionable and simpler counterfactuals than the current\\nstate-of-the-art algorithms. We also test our algorithm with a real-world\\nEnvironmental Protection Agency dataset, facilitating a more efficient and\\nequitable study of policies to improve the quality of life in United States of\\nAmerica counties. Our proposal captures the interaction of variables, ensuring\\nequity in decisions, as policies to improve certain domains of study (air,\\nwater quality, etc.) can be detrimental in others. In particular, the\\nsociodemographic domain is often involved, where we find important variables\\nrelated to the ongoing housing crisis that can potentially have a severe\\nnegative impact on communities.\n","Name: abstract, dtype: object"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>abstract</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Large Reasoning Models (LRMs) have introduced a new paradigm in AI by\\nenabling models to ``think before responding\" via chain-of-thought reasoning.\\nHowever, the absence of open and reproducible recipes for building\\nreasoning-centric medical LMMs hinders community-wide research, analysis, and\\ncomparison. In this paper, we present MedVLThinker, a suite of simple yet\\nstrong baselines. Our fully open recipe consists of: (1) systematic data\\ncuration for both text-only and image-text medical data, filtered according to\\nvarying levels of reasoning difficulty, and (2) two training paradigms:\\nSupervised Fine-Tuning (SFT) on distilled reasoning traces and Reinforcement\\nLearning with Verifiable Rewards (RLVR) based on final answer correctness.\\nAcross extensive experiments on the Qwen2.5-VL model family (3B, 7B) and six\\nmedical QA benchmarks, we find that RLVR consistently and significantly\\noutperforms SFT. Additionally, under the RLVR framework, a key,\\ncounter-intuitive finding is that training on our curated text-only reasoning\\ndata provides a more substantial performance boost than training on multimodal\\nimage-text data. Our best open 7B model, trained using the RLVR recipe on\\ntext-only data, establishes a new state-of-the-art on existing public VQA\\nbenchmarks, surpassing all previous open-source medical LMMs. Furthermore,\\nscaling our model to 32B achieves performance on par with the proprietary\\nGPT-4o. We release all curated data, models, and code to provide the community\\nwith a strong, open foundation for future research in multimodal medical\\nreasoning.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>While large language models (LLMs) have achieved remarkable performance\\nacross a wide range of tasks, their massive scale incurs prohibitive\\ncomputational and memory costs for pre-training from scratch. Recent studies\\nhave investigated the use of low-rank parameterization as a means of reducing\\nmodel size and training cost. In this context, sparsity is often employed as a\\ncomplementary technique to recover important information lost in low-rank\\ncompression by capturing salient features in the residual space. However,\\nexisting approaches typically combine low-rank and sparse components in a\\nsimplistic or ad hoc manner, often resulting in undesirable performance\\ndegradation compared to full-rank training. In this paper, we propose\\n\\textbf{LO}w-rank and \\textbf{S}parse pre-\\textbf{T}raining (\\textbf{LOST}) for\\nLLMs, a novel method that ingeniously integrates low-rank and sparse structures\\nto enable effective training of LLMs from scratch under strict efficiency\\nconstraints. LOST applies singular value decomposition to weight matrices,\\npreserving the dominant low-rank components, while allocating the remaining\\nsingular values to construct channel-wise sparse components to complement the\\nexpressiveness of low-rank training. We evaluate LOST on LLM pretraining\\nranging from 60M to 7B parameters. Our experiments show that LOST achieves\\ncompetitive or superior performance compared to full-rank models, while\\nsignificantly reducing both memory and compute overhead. Moreover, Code is\\navailable at\\n\\href{https://github.com/JiaxiLi1/LOST-Low-rank-and-Sparse-Training-for-Large-Language-Models}{LOST\\nRepo}</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>The development of accurate and efficient machine learning models for\\npredicting the structure and properties of molecular crystals has been hindered\\nby the scarcity of publicly available datasets of structures with property\\nlabels. To address this challenge, we introduce the Open Molecular Crystals\\n2025 (OMC25) dataset, a collection of over 27 million molecular crystal\\nstructures containing 12 elements and up to 300 atoms in the unit cell. The\\ndataset was generated from dispersion-inclusive density functional theory (DFT)\\nrelaxation trajectories of over 230,000 randomly generated molecular crystal\\nstructures of around 50,000 organic molecules. OMC25 comprises diverse chemical\\ncompounds capable of forming different intermolecular interactions and a wide\\nrange of crystal packing motifs. We provide detailed information on the\\ndataset's construction, composition, structure, and properties. To demonstrate\\nthe quality and use cases of OMC25, we further trained and evaluated\\nstate-of-the-art open-source machine learning interatomic potentials. By making\\nthis dataset publicly available, we aim to accelerate the development of more\\naccurate and efficient machine learning models for molecular crystals.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Diffusion policies excel at robotic manipulation by naturally modeling\\nmultimodal action distributions in high-dimensional spaces. Nevertheless,\\ndiffusion policies suffer from diffusion representation collapse: semantically\\nsimilar observations are mapped to indistinguishable features, ultimately\\nimpairing their ability to handle subtle but critical variations required for\\ncomplex robotic manipulation. To address this problem, we propose D2PPO\\n(Diffusion Policy Policy Optimization with Dispersive Loss). D2PPO introduces\\ndispersive loss regularization that combats representation collapse by treating\\nall hidden representations within each batch as negative pairs. D2PPO compels\\nthe network to learn discriminative representations of similar observations,\\nthereby enabling the policy to identify subtle yet crucial differences\\nnecessary for precise manipulation. In evaluation, we find that early-layer\\nregularization benefits simple tasks, while late-layer regularization sharply\\nenhances performance on complex manipulation tasks. On RoboMimic benchmarks,\\nD2PPO achieves an average improvement of 22.7% in pre-training and 26.1% after\\nfine-tuning, setting new SOTA results. In comparison with SOTA, results of\\nreal-world experiments on a Franka Emika Panda robot show the excitingly high\\nsuccess rate of our method. The superiority of our method is especially evident\\nin complex tasks. Project page: https://guowei-zou.github.io/d2ppo/</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>We demonstrate that a single 3x3 convolutional kernel can produce emergent\\naudio effects when trained on 200 samples from a personalized corpus. We\\nachieve this through two key techniques: (1) Conditioning Aware Kernels (CAK),\\nwhere output = input + (learned_pattern x control), with a soft-gate mechanism\\nsupporting identity preservation at zero control; and (2) AuGAN (Audit GAN),\\nwhich reframes adversarial training from \"is this real?\" to \"did you apply the\\nrequested value?\" Rather than learning to generate or detect forgeries, our\\nnetworks cooperate to verify control application, discovering unique\\ntransformations. The learned kernel exhibits a diagonal structure creating\\nfrequency-dependent temporal shifts that are capable of producing musical\\neffects based on input characteristics. Our results show the potential of\\nadversarial training to discover audio transformations from minimal data,\\nenabling new approaches to effect design.</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Crystal Structure Prediction (CSP) of molecular crystals plays a central role\\nin applications, such as pharmaceuticals and organic electronics. CSP is\\nchallenging and computationally expensive due to the need to explore a large\\nsearch space with sufficient accuracy to capture energy differences of a few\\nkJ/mol between polymorphs. Dispersion-inclusive density functional theory (DFT)\\nprovides the required accuracy but its computational cost is impractical for a\\nlarge number of putative structures. We introduce FastCSP, an open-source,\\nhigh-throughput CSP workflow based on machine learning interatomic potentials\\n(MLIPs). FastCSP combines random structure generation using Genarris 3.0 with\\ngeometry relaxation and free energy calculations powered entirely by the\\nUniversal Model for Atoms (UMA) MLIP. We benchmark FastCSP on a curated set of\\n28 mostly rigid molecules, demonstrating that our workflow consistently\\ngenerates known experimental structures and ranks them within 5 kJ/mol per\\nmolecule of the global minimum. Our results demonstrate that universal MLIPs\\ncan be used across diverse compounds without requiring system-specific tuning.\\nMoreover, the speed and accuracy afforded by UMA eliminate the need for\\nclassical force fields in the early stages of CSP and for final re-ranking with\\nDFT. The open-source release of the entire FastCSP workflow significantly\\nlowers the barrier to accessing CSP. CSP results for a single system can be\\nobtained within hours on tens of modern GPUs, making high-throughput crystal\\nstructure prediction feasible for a broad range of scientific applications.</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Efficient management of aircraft maintenance hangars is a critical\\noperational challenge, involving complex, interdependent decisions regarding\\naircraft scheduling and spatial allocation. This paper introduces a novel\\ncontinuous-time mixed-integer linear programming (MILP) model to solve this\\nintegrated spatio-temporal problem. By treating time as a continuous variable,\\nour formulation overcomes the scalability limitations of traditional\\ndiscrete-time approaches. The performance of the exact model is benchmarked\\nagainst a constructive heuristic, and its practical applicability is\\ndemonstrated through a custom-built visualization dashboard. Computational\\nresults are compelling: the model solves instances with up to 25 aircraft to\\nproven optimality, often in mere seconds, and for large-scale cases of up to 40\\naircraft, delivers high-quality solutions within known optimality gaps. In all\\ntested scenarios, the resulting solutions consistently and significantly\\noutperform the heuristic, which highlights the framework's substantial economic\\nbenefits and provides valuable managerial insights into the trade-off between\\nsolution time and optimality.</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Large-scale quantum systems require optical coherence between distant quantum\\ndevices, necessitating spectral indistinguishability. Scalable solid-state\\nplatforms offer promising routes to this goal. However, environmental\\ndisorders, including dephasing, spectral diffusion, and spin-bath interactions,\\ninfluence the emitters' spectra and deteriorate the coherence. Using\\nstatistical theory, we identify correlations in spectral diffusion from slowly\\nvarying environmental coupling, revealing predictable dynamics extendable to\\nother disorders. Importantly, this could enable the development of an\\nanticipatory framework for forecasting and decoherence engineering in remote\\nquantum emitters. To validate this framework, we demonstrate that a machine\\nlearning model trained on limited data can accurately forecast unseen spectral\\nbehavior. Realization of such a model on distinct quantum emitters could reduce\\nthe spectral shift by factors $\\approx$ 2.1 to 15.8, depending on emitter\\nstability, compared to no prediction. This work presents, for the first time,\\nthe application of anticipatory systems and replica theory to quantum\\ntechnology, along with the first experimental demonstration of internal\\nprediction that generalizes across multiple quantum emitters. These results\\npave the way for real-time decoherence engineering in scalable quantum systems.\\nSuch capability could lead to enhanced optical coherence and multi-emitter\\nsynchronization, with broad implications for quantum communication,\\ncomputation, imaging, and sensing.</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>In the uniformity testing task, an algorithm is provided with samples from an\\nunknown probability distribution over a (known) finite domain, and must decide\\nwhether it is the uniform distribution, or, alternatively, if its total\\nvariation distance from uniform exceeds some input distance parameter. This\\nquestion has received a significant amount of interest and its complexity is,\\nby now, fully settled. Yet, we argue that it fails to capture many scenarios of\\ninterest, and that its very definition as a gap problem in terms of a\\nprespecified distance may lead to suboptimal performance.\\n  To address these shortcomings, we introduce the problem of uniformity\\ntracking, whereby an algorithm is required to detect deviations from uniformity\\n(however they may manifest themselves) using as few samples as possible, and be\\ncompetitive against an optimal algorithm knowing the distribution profile in\\nhindsight. Our main contribution is a\\n$\\operatorname{polylog}(\\operatorname{opt})$-competitive uniformity tracking\\nalgorithm. We obtain this result by leveraging new structural results on\\nPoisson mixtures, which we believe to be of independent interest.</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Counterfactual explanations study what should have changed in order to get an\\nalternative result, enabling end-users to understand machine learning\\nmechanisms with counterexamples. Actionability is defined as the ability to\\ntransform the original case to be explained into a counterfactual one. We\\ndevelop a method for actionable counterfactual explanations that, unlike\\npredecessors, does not directly leverage training data. Rather, data is only\\nused to learn a density estimator, creating a search landscape in which to\\napply path planning algorithms to solve the problem and masking the endogenous\\ndata, which can be sensitive or private. We put special focus on estimating the\\ndata density using Bayesian networks, demonstrating how their enhanced\\ninterpretability is useful in high-stakes scenarios in which fairness is\\nraising concern. Using a synthetic benchmark comprised of 15 datasets, our\\nproposal finds more actionable and simpler counterfactuals than the current\\nstate-of-the-art algorithms. We also test our algorithm with a real-world\\nEnvironmental Protection Agency dataset, facilitating a more efficient and\\nequitable study of policies to improve the quality of life in United States of\\nAmerica counties. Our proposal captures the interaction of variables, ensuring\\nequity in decisions, as policies to improve certain domains of study (air,\\nwater quality, etc.) can be detrimental in others. In particular, the\\nsociodemographic domain is often involved, where we find important variables\\nrelated to the ongoing housing crisis that can potentially have a severe\\nnegative impact on communities.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> object</label>"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["summarization_result=summarizer(abstract)"],"metadata":{"id":"-Du0evD7mPJb","executionInfo":{"status":"ok","timestamp":1754387105694,"user_tz":-345,"elapsed":24095,"user":{"displayName":"Dinesh Tamang","userId":"12691506856444135406"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["summarized_text=[]\n","for text in abstract:\n","  summarization_result=summarizer(text)\n","  result=summarization_result[0][\"summary_text\"]\n","  summarized_text.append(result)"],"metadata":{"id":"UgOyRRWvoVR3","executionInfo":{"status":"ok","timestamp":1754387838368,"user_tz":-345,"elapsed":199169,"user":{"displayName":"Dinesh Tamang","userId":"12691506856444135406"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["summarized_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nTtRCzTsmpyM","executionInfo":{"status":"ok","timestamp":1754387928293,"user_tz":-345,"elapsed":18,"user":{"displayName":"Dinesh Tamang","userId":"12691506856444135406"}},"outputId":"d65bfdc6-31eb-4690-d45f-2d5c759843df"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Large Reasoning Models (LRMs) have introduced a new paradigm in AI by enabling models to think before responding. The absence of open and reproducible recipes for building LMMs hinders community-wide research, analysis, and comparison. We present MedVLThinker, a suite of simple yet strong baselines.',\n"," 'Large language models (LLMs) have achieved remarkable performanceacross a wide range of tasks. However, their massive scale incurs prohibitive computational and memory costs for pre-training from scratch. LOST is a novel method that ingeniously integrates low-rank and sparse structures to enable effective training of LLMs.',\n"," 'The Open Molecular Crystals2025 (OMC25) dataset is a collection of over 27 million molecular crystalstructures containing 12 elements and up to 300 atoms in the unit cell. OMC25 comprises diverse chemicalcompounds capable of forming different intermolecular interactions and a wide range of crystal packing motifs.',\n"," 'Diffusion policies excel at robotic manipulation by naturally modelingmultimodal action distributions in high-dimensional spaces. Nevertheless, they suffer from diffusion representation collapse. D2PPO introduces Dispersive loss regularization that combats representation collapse by treating hidden representations within each batch as negative pairs. Early-layer regularization benefits simple tasks, while late- layer regularization sharply enhances performance on complex manipulation tasks.',\n"," 'We demonstrate that a single 3x3 convolutional kernel can produce emergentaudio effects when trained on 200 samples from a personalized corpus. The learned kernel exhibits a diagonal structure creating temporal shifts that are capable of producing musicaleffects based on input characteristics. Our results show the potential of ofadversarial training to discover audio transformations from minimal data, enabling new approaches to effect design.',\n"," 'Crystal Structure Prediction (CSP) of molecular crystals plays a central role in applications, such as pharmaceuticals and organic electronics. CSP is computationally expensive due to the need to explore a large search space with sufficient accuracy to capture energy differences. We introduce FastCSP, an open-source, high-throughput CSP workflow based on machine learning interatomic potentials(MLIPs)',\n"," 'The paper introduces a novelcontinuous-time mixed-integer linear programming (MILP) model to solve this problem. By treating time as a continuous variable, the formulation overcomes the scalability limitations of traditional discrete-time approaches. The model solves instances with up to 25 aircraft toproven optimality, often in mere seconds, and for large-scale cases of up to 40 aircraft.',\n"," \"Large-scale quantum systems require optical coherence between distant quantumdevices. Environmental disorders, including dephasing, spectral diffusion, and spin-bath interactions, influence the emitters' spectra and deteriorate the coherence. This work presents, for the first time, the application of anticipatory systems and replica theory to quantum technology.\",\n"," 'Uniformity tracking is a problem of how to detect deviations from uniformity using as few samples as possible. Our main contribution is a competitive uniformity tracking algorithm. We obtain this result by leveraging new structural results on Poisson mixtures, which we believe to be of independent interest.',\n"," 'Counterfactual explanations study what should have changed in order to get an alternative result. We develop a method for actionable counterfactual explanation that does not directly leverage training data. Data is only used to learn a density estimator, creating a search landscape in which to apply path planning algorithms to solve the problem.']"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":[],"metadata":{"id":"ynTiwfyPncgb"},"execution_count":null,"outputs":[]}]}